\chapter{Results}

In this chapter I will provide a layout of the experiments, which I have set up, in order to verify and present the functionality of the implementation as a whole. This includes testing of all modules contained in the implementation, as well as the final demonstration, that a model generated manually, can be replicated automatically.

\section{Testing}

Testing of the implementation has been divided into two parts, one of which is detailed in Section~\ref{ssec:Testing the Manual Model Creator}, the other in Section~\ref{ssec:Testing the Automatic Model Creator}.

\subsection{Testing the Manual Model Creator}
The manual model creator module contained in the file \ttt{mmods.erl}, exports 11 functions, of which 7 are model creation functions\footnote{\lstinline{start/1}, \lstinline{add_relation/2}, \lstinline{add_dependency/3}, \lstinline{add_info/2}, \lstinline{remove_info/2}, \lstinline{transfer_info/3}}, 4 are data-fetching functions\footnote{\lstinline{get_state/1}, \lstinline{get_type/1}, \lstinline{get_relations/1}, \lstinline{get_info/1}} and a single one is a simulation function\footnote{\lstinline{request_info/4}}.

All testing of the mmods module has been contained in the \ttt{tests.erl} file, which includes multiple function-specific tests for each API function, exported from the mmods module. After compilation, all tests can be run in an Erlang shell, either as the normal zero-input functions they are, or as the \linebreak \lstinline{main_funcs/0} function, which encapsulates all created function-specific test cases. All tests are created to return the atom \ttt{true} if they succeed, or the corresponding error message, if they do not. All API-function-specific tests returned true, indicating their correctness. The getter functions were only tested with a single case, \lstinline{get_all/0}, due to their implementation being extremely simple.

The remaining part of the \ttt{tests.erl}-file includes the scenario-oriented tests. As the description entails, these tests describe the outcome of seven scenarios; one for every scenario-function test. The tests, contained in this section of the file are:

\begin{description}
  \item[{multiple\_coms/0}]\ \\
    This test case shows that a single service is able to determine which company to draw information from in an information request. The service \ttt{Serv} is connected to the three companies \ttt{Com1}, \ttt{Com2}, and \ttt{Com3}, which hold the atoms \ttt{this}, \ttt{is}, and \ttt{correct} respectively. For each request, as \ttt{Ship} requests the same service entity \ttt{Serv} for the three atoms, \ttt{Serv} must select which company to fetch the data from.
  \item[{multiple\_serv/1}]\ \\
    This test case shows that multiple service entities can link a ship entity and a company entity. The ship entity \ttt{Ship} and the company entity \ttt{Comp} are linked thrice by the service entities \ttt{Ser1}, \ttt{Ser2}, and \ttt{Ser3}, and the three atoms \ttt{this}, \ttt{is}, and \ttt{correct} are requested. The three atoms are requested one at a time, through each relation, and no matter the order, the right combination is fetched. This function is executed six times; one for each permutation of the order in which to request to the three service entities.
  \item[{service\_choose\_company/0}]\ \\
    This test case shows that when a service entity is linked to several company entities, each containing different data, it is able to determine which company to fetch data from. Here the ship \ttt{Ship} is mutually linked to \ttt{Serv}, which is then mutually linked to companies \ttt{Com[1,..,5]}. As \ttt{Ship} requests the atom \ttt{c}, \ttt{Serv} will have to determine that \ttt{Com1} holds the relevant information, and thus this is transfered to \ttt{Ship}.
  \item[{bad\_connection\_from/0}]\ \\
    This test case shows what happens to a request when the service entity is linked to a company entity, without the connection being mutual. In this case, as \ttt{Shp1} and \ttt{Shp2} request \ttt{Serv}, \ttt{Serv} passes the requests on to \ttt{Comp}. \ttt{Serv} is able to make the requests, however, as no channels of communication are set up from \ttt{Comp} to \ttt{Serv}, no information is able to be returned, and thus no ships receive information.
  \item[{bad\_connection\_to/0}]\ \\
    This test case works similar to \ttt{bad\_connection\_from/0}, however, in this case, the connection from \ttt{Serv} to \ttt{Comp} is missing. Thus, \ttt{Serv} cannot find the correct entity to pass the request on to, and thus no ships receive information.
  \item[{ok\_connection/0}]\ \\
    This test case works as the last two test cases should ideally have worked. That is, two ship entities request a service entity, which fetches data from a company entity, and thus, data is returned to the ship entities.
  \item[{first\_come\_first\_served/0}]\ \\
    This test case shows that information is removed from a service entity, after it is sent. In this case, the two ship entities, \ttt{Shp1} and \ttt{Shp2} are both mutually connected to the service entity \ttt{Serv}. The service entity holds the atom \ttt{a\_steak}, and when both ship entities request said atom, it will be distributed to whomever requested first. 
\end{description}
\noindent
The scenario-oriented test cases are all included in the wrapper function \ttt{main\_scenarios/0}, which, when run, yields that all cases pass. The scenarios wrapper function is included in the top-level wrapper function, and thus, to execute \tit{all} tests, function-oriented or scenario-oriented, simply execute \command{tests:main().}

\subsection{Testing the Automatic Model Creator}

The automatic model creation algorithm makes use of the mmods module, and as this has been tested for correctness in Section~\ref{ssec:Testing the Manual Model Creator}, it is fair to assume that this module will also function correctly in the context of the automatic model creator. 

The two modules that distinguish the automatic model creator from its manual counterpart is the parser and the interpreter. As the parser is a standardized xml-to-Erlang, there is no need to check for edge-cases, correlating directly to the current implementation, as there are none. Therefore the parser is tested with the function \lstinline{parse_tests/0}, which includes all test cases. The cases tested for are correct handling of strings, integers, lists, multiple sub-tags in one tag, a tag occurring in another tag with the same name, and handling of spaces. The test is run with \lstinline{tests:parse_tests().} in an Erlang shell, which will reveal that all tests pass.

One test that does not pass, is \lstinline{test_interp_anonymous_function/0}. This is due to the fact that handling of anonymous functions is not implemented at the time of writing. Support hereof would need to be handled in the \linebreak \lstinline{aux:token/1}-function, as this is the mechanism that translates functions in the Erlang-term, resulting from \lstinline{fparse/1}.

\section{Experiments}

The primary goal of the project is to construct maritime models, describing maritime services, in the shape of finite state machines, both manually and automatically, followed by an assessment of the advantages and disadvantages of each type. As summarized in Section~\ref{sec:Summary: Advantages and Disadvantages}, manual model-building provides more control to the author, while automatic model building allows for more streamlining in the model-building process. Thus, as each method provides unique advantages to the process, a feasible metric of judging the products of each method is their respective attributes. That is, which FSM is able to describe scenarios to the highest degree. In order to determine this, I will compare the results of each model building method, starting with the example, given in Figure~\ref{fig:modelExProtocol}.

\subsection{Model Equivalence}

Figures~\ref{fig:protocolManual} and~\ref{fig:protocolAutomatic} display the results of manual and automatic model creation respectively. By manually inspecting them, it can be seen that the only variance between the two is the process IDs, and despite of this, the relationships between the entities, are evidently equal in the two models. Also, from manual inspection, it can be seen that information, types and dependencies, distributed between entities are also equal to that of their manual/automatic counterparts.\\[0.25 cm]
\begin{figure}[h]
  \begin{lstlisting}[keywordstyle={}]
[{company,[{<0.79.0>,[]}],<0.80.0>,["map"]},
 {service,[{<0.78.0>,[]},{<0.80.0>,[]}],<0.79.0>,[]},
 {ship,[{<0.79.0>,[fun aux:user/1,fun aux:psswd/1]}],
       <0.78.0>,
       ["map"]}]
  \end{lstlisting}
  \caption{Maritime model, resulting of executing the commands, contained within the function \ttt{examples:protocol}}
  \label{fig:protocolManual}
\end{figure}
\ \\[0.25 cm]
\begin{figure}[h]
  \begin{lstlisting}[keywordstyle={}]
[{company,[{<0.84.0>,[]}],<0.83.0>,["map"]},
 {service,[{<0.85.0>,[]},{<0.83.0>,[]}],<0.84.0>,[]},
 {ship,[{<0.84.0>,[fun aux:user/1,fun aux:psswd/1]}],
       <0.85.0>,
       ["map"]}]
  \end{lstlisting}
  \caption{Maritime model, resulting of interpreting the file \ttt{protocol.xml} with \lstinline{main:parse_and_interpret('xml/protocol.xml')}}
  \label{fig:protocolAutomatic}
\end{figure}
\newpage
\noindent
A visual representation of the points described is displayed in Figure~\ref{fig:protocolVisual}, where~\ref{subfig:protocolManualVisual} represents the manually created model, and~\ref{subfig:protocolAutomaticVisual} represents the automatically created model. In both subfigures, nodes symbolize entities, containing three fields. The first line in each entity node represents its type, the second its unique ID, with the third representing the information held by the entity. All edges in the figures are oriented, symbolizing relations from one entity to another. Functions displayed beside a relation, represents a dependency, associated with that relation. If not evident in Figures~\ref{fig:protocolManual} and~\ref{fig:protocolAutomatic}, Figure~\ref{fig:protocolVisual} clearly show how the collection of entities' states are uniform in relation to their counterparts'.

\begin{figure}[h]
  \begin{subfigure}{.48\textwidth}
    \begin{tikzpicture}[->,>=stealth', node distance=2.8 cm, thick]
    \tikzstyle{every state}=[rectangle,
                       rounded corners,
                       rectangle,
                       top color=white,
                       bottom color=gray!50,
                       align=center]
    
    \tikzstyle{every path}=[->,
                            gray!150,
                            >=stealth,
                            text=black,
                            bend right,
                            left]

      \node[state] (A) []           {ship\\   $<0.78.0>$\\$["map"]$};
      \node[state] (B) [below of=A] {service\\$<0.79.0>$\\ - };
      \node[state] (C) [below of=B] {company\\$<0.80.0>$\\$["map"]$};
  
      \path (A) edge[] node[align=left]{fun aux:user/1\\
                                        fun aux:psswd/1} (B)
            (B) edge[] node{} (A)
                edge[] node{} (C) 
            (C) edge[] node{} (B);
    \end{tikzpicture}
    \caption{}
    \label{subfig:protocolManualVisual}
  \end{subfigure}
  \begin{subfigure}{.48\textwidth}
    \begin{tikzpicture}[->,>=stealth', node distance=2.8 cm, thick]
    \tikzstyle{every state}=[rectangle,
                       rounded corners,
                       rectangle,
                       top color=white,
                       bottom color=gray!50,
                       align=center]
    
    \tikzstyle{every path}=[->,
                            gray!150,
                            >=stealth,
                            text=black,
                            bend right,
                            left]

      \node[state] (A) []           {ship\\   $<0.85.0>$\\$["map"]$};
      \node[state] (B) [below of=A] {service\\$<0.84.0>$\\ - };
      \node[state] (C) [below of=B] {company\\$<0.83.0>$\\$["map"]$};
  
      \path (A) edge[] node[align=left]{fun aux:user/1\\
                                        fun aux:psswd/1} (B)
            (B) edge[] node{} (A)
                edge[] node{} (C)
            (C) edge[] node{} (B);
    \end{tikzpicture}
    \caption{}
    \label{subfig:protocolAutomaticVisual}
  \end{subfigure}
  \caption{Visual representation of Figures~\ref{fig:protocolManual}, and~\ref{fig:protocolAutomatic}.}
  \label{fig:protocolVisual}
\end{figure}
Having concluded that the models\footnote{Collections of all states in the FSM}, described in Figures~\ref{fig:protocolManual}, and~\ref{fig:protocolAutomatic}, are equal, in order for their FSMs to be equivalent, all available \tit{actions} correlating to the states must also be equal. To determine if this is the case, I will look to the functionality of the manual, as well as the automatic model creator. 

The functionality of the automatic implementation is built to directly utilize the manual model building module, and thus their functionalities are near identical. They are only limited by the functionality of the parser and interpreter's ability to feed instructions to \ttt{mmods.erl}, such as the example given in Section~\ref{ssec:Testing the Automatic Model Creator}.
\newpage
\subsubsection{Further Examples of Model Equivalence}

In order to verify that the example, described above in Section~\ref{ssec:Model Equivalence} is not a unique occurrence, the function \lstinline{equiv_models/2} has been created. This function compares two maritime models, according to the metrics used, when comparing models in Figure~\ref{fig:protocolVisual}; Types, constraint functions, and information have to exactly match, while relations have to match mapped values. The function \lstinline{equiv_models_tests/0} utilizes the model comparer function, in order to test that the protocol example holds true with other examples as well. The examples given to \lstinline{equiv_models_tests/0}, are all models created manually in the file \ttt{examples.erl}, as well as their automatic counterparts, created in the 'xml' folder. All test cases passed, further proving the implementation's ability to create equivalent maritime models.
